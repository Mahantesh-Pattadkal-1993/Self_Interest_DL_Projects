{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert-Sentiment Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d34e5161c6324aefbebcf090ec9a5832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_032090c2ecf84c71ba9d7723d113c9a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b192d74382f146baa3c47397d52d5857",
              "IPY_MODEL_ab1ca262087740cbb83a9a652f2cbf59"
            ]
          }
        },
        "032090c2ecf84c71ba9d7723d113c9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b192d74382f146baa3c47397d52d5857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_65c04bbc53ab4e4fae054eaa8bf75b7f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63605dbd428f4039800ba04a69cfff31"
          }
        },
        "ab1ca262087740cbb83a9a652f2cbf59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6c9905695fa4b62bdf9a0ea67dc2943",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 814kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cd8a542c390416d80e649d92fd6e226"
          }
        },
        "65c04bbc53ab4e4fae054eaa8bf75b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63605dbd428f4039800ba04a69cfff31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6c9905695fa4b62bdf9a0ea67dc2943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cd8a542c390416d80e649d92fd6e226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc888b4fe0044586b58ab9ebb4310d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c4b2154244f43538e6e8aa0eb1f531d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e6e9c01205c34b7abc4e8dac855ff6f7",
              "IPY_MODEL_d21a106ba6784ca6b2b18e6397c57a19"
            ]
          }
        },
        "5c4b2154244f43538e6e8aa0eb1f531d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6e9c01205c34b7abc4e8dac855ff6f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfd7eccf96c941bdba96af2d5ae2a420",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fddbdd583aa472c9d39de7a05261ace"
          }
        },
        "d21a106ba6784ca6b2b18e6397c57a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a81c8215ab54f9d961f592da2376551",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.73MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec24788a0dcf4e4fb855f4f3bd2f36c0"
          }
        },
        "cfd7eccf96c941bdba96af2d5ae2a420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fddbdd583aa472c9d39de7a05261ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a81c8215ab54f9d961f592da2376551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec24788a0dcf4e4fb855f4f3bd2f36c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt4LkjNuZLEA"
      },
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QtCrrY-Ya4f"
      },
      "source": [
        "The notebook is derived from the 'https://skimai.com/fine-tuning-bert-for-sentiment-analysis/'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMmo-UgBZMkP",
        "outputId": "73dcfb5a-04ba-4a18-d181-ddb75ce1aac1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxVP1O3OZaPz"
      },
      "source": [
        "# Download data\n",
        "import requests\n",
        "request = requests.get(\"https://drive.google.com/uc?export=download&id=1wHt8PsMLsfX5yNSqrt2fSTcb8LEiclcf\")\n",
        "with open(\"data.zip\", \"wb\") as file:\n",
        "    file.write(request.content)\n",
        "\n",
        "# Unzip data\n",
        "import zipfile\n",
        "with zipfile.ZipFile('data.zip') as zip:\n",
        "    zip.extractall('data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "cDvelv93Zhp4",
        "outputId": "e8a7dd7b-9532-45c7-f042-d000986083f1"
      },
      "source": [
        " # Load data and set labels\n",
        "data_complaint = pd.read_csv('data/complaint1700.csv')\n",
        "data_complaint['label'] = 0\n",
        "data_non_complaint = pd.read_csv('data/noncomplaint1700.csv')\n",
        "data_non_complaint['label'] = 1\n",
        "\n",
        "# Concatenate complaining and non-complaining data\n",
        "data = pd.concat([data_complaint, data_non_complaint], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Drop 'airline' column\n",
        "data.drop(['airline'], inplace=True, axis=1)\n",
        "\n",
        "# Display 5 random samples\n",
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2760</th>\n",
              "      <td>101495</td>\n",
              "      <td>Southwest Airlines Can Use Planes That Missed ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>155357</td>\n",
              "      <td>@AmericanAir Never will I fly with you after t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2973</th>\n",
              "      <td>126308</td>\n",
              "      <td>@julie2768 @SouthwestAir help my friend. My is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>20300</td>\n",
              "      <td>@united 1st Class bump LGA. Promised Club pass...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>99324</td>\n",
              "      <td>Terrible service @AmericanAir no mobile app no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet  label\n",
              "2760  101495  Southwest Airlines Can Use Planes That Missed ...      1\n",
              "282   155357  @AmericanAir Never will I fly with you after t...      0\n",
              "2973  126308  @julie2768 @SouthwestAir help my friend. My is...      1\n",
              "342    20300  @united 1st Class bump LGA. Promised Club pass...      0\n",
              "1519   99324  Terrible service @AmericanAir no mobile app no...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qQs3wS-Z0Kv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.tweet.values\n",
        "y = data.label.values\n",
        "\n",
        "X_train, X_val, y_train, y_val =\\\n",
        "    train_test_split(X, y, test_size=0.1, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWRs7dihaejJ",
        "outputId": "b3cea963-a042-4ef8-de92-05738a7ebfed"
      },
      "source": [
        "print (len(X_train)) #Number of rows for training "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "LwLOOPZtZ49q",
        "outputId": "0000eba5-40c3-403d-acea-5f9b80367d02"
      },
      "source": [
        "# Load test data\n",
        "test_data = pd.read_csv('data/test_data.csv')\n",
        "\n",
        "# Keep important columns\n",
        "test_data = test_data[['id', 'tweet']]\n",
        "\n",
        "# Display 5 samples from the test data\n",
        "test_data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>36428</td>\n",
              "      <td>Perils of travel. @united flight to dc isn't o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2287</th>\n",
              "      <td>87809</td>\n",
              "      <td>@TheYumYumFoodie @united that's awful! :(</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3612</th>\n",
              "      <td>136379</td>\n",
              "      <td>@SouthwestAir I miss flying you! Wish you'd co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1694</th>\n",
              "      <td>65503</td>\n",
              "      <td>Not only did @SouthwestAir lose our bags on th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1116</th>\n",
              "      <td>43855</td>\n",
              "      <td>@united you are the worst airline ever. Make p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet\n",
              "916    36428  Perils of travel. @united flight to dc isn't o...\n",
              "2287   87809          @TheYumYumFoodie @united that's awful! :(\n",
              "3612  136379  @SouthwestAir I miss flying you! Wish you'd co...\n",
              "1694   65503  Not only did @SouthwestAir lose our bags on th...\n",
              "1116   43855  @united you are the worst airline ever. Make p..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtIJREpXZ9vv",
        "outputId": "38881e53-59aa-4cfd-8a94-8626000c3ee7"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIS2-DKmaCxm"
      },
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEBKDpSVfOj1",
        "outputId": "62580bf3-159f-43f6-cb02-f4993e9a9253"
      },
      "source": [
        "# Print sentence 0\n",
        "print('Original: ', X[0])\n",
        "print('Processed: ', text_preprocessing(X[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  @united I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on &amp; check in. Can you help?\n",
            "Processed:  I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on & check in. Can you help?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d34e5161c6324aefbebcf090ec9a5832",
            "032090c2ecf84c71ba9d7723d113c9a7",
            "b192d74382f146baa3c47397d52d5857",
            "ab1ca262087740cbb83a9a652f2cbf59",
            "65c04bbc53ab4e4fae054eaa8bf75b7f",
            "63605dbd428f4039800ba04a69cfff31",
            "c6c9905695fa4b62bdf9a0ea67dc2943",
            "9cd8a542c390416d80e649d92fd6e226"
          ]
        },
        "id": "vAN1_a3AhSk3",
        "outputId": "4e2a1185-ca4e-4fe6-9c9c-1af805d2b963"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d34e5161c6324aefbebcf090ec9a5832",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "dc888b4fe0044586b58ab9ebb4310d94",
            "5c4b2154244f43538e6e8aa0eb1f531d",
            "e6e9c01205c34b7abc4e8dac855ff6f7",
            "d21a106ba6784ca6b2b18e6397c57a19",
            "cfd7eccf96c941bdba96af2d5ae2a420",
            "8fddbdd583aa472c9d39de7a05261ace",
            "5a81c8215ab54f9d961f592da2376551",
            "ec24788a0dcf4e4fb855f4f3bd2f36c0"
          ]
        },
        "id": "gp_7lrXuEY3q",
        "outputId": "91be139e-b32d-4d0e-dbd4-ef55f84cc978"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc888b4fe0044586b58ab9ebb4310d94",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy2bKzohh7Db",
        "outputId": "7083686e-065c-4a9c-8881-80bd154c6e40"
      },
      "source": [
        "# Concatenate train data and test data\n",
        "all_tweets = np.concatenate([data.tweet.values, test_data.tweet.values])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GZtKml3h_Qa",
        "outputId": "86f51475-0dc6-4f62-a995-06b18656cb06"
      },
      "source": [
        "# Specify `MAX_LEN`, we are keeping this to 64 instead of 68\n",
        "MAX_LEN = 64\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  @united I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on &amp; check in. Can you help?\n",
            "Token IDs:  [101, 1045, 1005, 1049, 2383, 3314, 1012, 7483, 1045, 2128, 8654, 2098, 2005, 2484, 2847, 2044, 1045, 2001, 4011, 2000, 4875, 1010, 2085, 1045, 2064, 1005, 1056, 8833, 2006, 1004, 4638, 1999, 1012, 2064, 2017, 2393, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw5rMmwKKa2L"
      },
      "source": [
        "**Making the data ready for training using the dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbe2HxT5iT56"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels) #loads the train_inputs, masks and labels corresponding to each other\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) #the data loader can be used to get instances one by one during training\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_fqUw2yGUHI",
        "outputId": "902a9759-7ecd-4f1e-84de-6c06f65d668c"
      },
      "source": [
        "#This code block is to show how the data is stored in the dataloaders\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "  #batch_counts +=1\n",
        "  # Load batch to GPU\n",
        "  b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "  print(b_input_ids.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Atwnsqy7KOMd"
      },
      "source": [
        "**Creating the Bert Model and adding one MLP classifier on top of it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9Fpk6JHKM7F"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "        #768 is the size of the output from the transformer\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA923nbySYvA"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5PqZ4tUYPik"
      },
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXALyR7MfN2v",
        "outputId": "f5e89742-7ca9-4f34-dd00-7690fd105bf3"
      },
      "source": [
        "#Finally start the training\n",
        "\n",
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True) #evaluation is true, so that the validation set will be used to evaluate the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.653855   |     -      |     -     |   7.74   \n",
            "   1    |   40    |   0.533028   |     -      |     -     |   7.54   \n",
            "   1    |   60    |   0.488258   |     -      |     -     |   7.68   \n",
            "   1    |   80    |   0.498773   |     -      |     -     |   7.49   \n",
            "   1    |   95    |   0.447733   |     -      |     -     |   5.38   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.529668   |  0.476418  |   79.55   |   37.15  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.339241   |     -      |     -     |   7.59   \n",
            "   2    |   40    |   0.323510   |     -      |     -     |   7.20   \n",
            "   2    |   60    |   0.287843   |     -      |     -     |   7.13   \n",
            "   2    |   80    |   0.267746   |     -      |     -     |   7.14   \n",
            "   2    |   95    |   0.336024   |     -      |     -     |   5.24   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.309858   |  0.503407  |   79.09   |   35.61  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.158224   |     -      |     -     |   7.55   \n",
            "   3    |   40    |   0.149206   |     -      |     -     |   7.25   \n",
            "   3    |   60    |   0.149399   |     -      |     -     |   7.29   \n",
            "   3    |   80    |   0.178013   |     -      |     -     |   7.30   \n",
            "   3    |   95    |   0.166348   |     -      |     -     |   5.36   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   0.159899   |  0.556729  |   80.80   |   36.09  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.091759   |     -      |     -     |   7.62   \n",
            "   4    |   40    |   0.091228   |     -      |     -     |   7.24   \n",
            "   4    |   60    |   0.095445   |     -      |     -     |   7.22   \n",
            "   4    |   80    |   0.092847   |     -      |     -     |   7.20   \n",
            "   4    |   95    |   0.097465   |     -      |     -     |   5.28   \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   0.093534   |  0.658608  |   78.52   |   35.88  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMWYUgZ5ioNy"
      },
      "source": [
        "Evaulation on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZPe6O56ir2M"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "\n",
        "    Returns the prediction in numpy array format. We do not provide labels here as we are not backpropagating loss, we are only predicting\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox0YArH5i8i2"
      },
      "source": [
        "#Function to evaluate the model\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "mCnE9p7KiwNe",
        "outputId": "b88ece4a-3f3f-47bf-c13c-0d1ff4edadb0"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.8839\n",
            "Accuracy: 78.82%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y_9HThQjLj9"
      },
      "source": [
        "How to predict on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "jHMhjph4jEx2",
        "outputId": "e1c26ba7-ff2f-45c2-d00e-baecd62e39da"
      },
      "source": [
        "test_data.sample(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>18654</td>\n",
              "      <td>Friends and family: Never fly @JetBlue.  Absol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1971</th>\n",
              "      <td>76265</td>\n",
              "      <td>@DeltaAssist @rogerioad I never have had a pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>672</td>\n",
              "      <td>First flight in weeks. Counting on you @Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2702</th>\n",
              "      <td>103263</td>\n",
              "      <td>\"@USAirways: You know that we can__t stay no m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>5137</td>\n",
              "      <td>@southwestair Here at SA Airport watching the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet\n",
              "471    18654  Friends and family: Never fly @JetBlue.  Absol...\n",
              "1971   76265  @DeltaAssist @rogerioad I never have had a pro...\n",
              "23       672  First flight in weeks. Counting on you @Americ...\n",
              "2702  103263  \"@USAirways: You know that we can__t stay no m...\n",
              "135     5137  @southwestair Here at SA Airport watching the ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSNLFWcHjR2V",
        "outputId": "fd70dbff-7096-42fb-8daa-30e92890a610"
      },
      "source": [
        "# Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(test_data.tweet)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)\n",
        "\n",
        "#we use the sequentialsampler here so that we get the prediction batch by batch for all the test samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h_p70gUjV9T",
        "outputId": "d0213d81-207a-4c6f-db70-7681ef50f587"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.9\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of tweets predicted non-negative: \", preds.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets predicted non-negative:  931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQQwnqCFjfqa",
        "outputId": "ba19d96f-898f-4c0d-8706-b2d2bf04153e"
      },
      "source": [
        "# probs contains the prediction probabilities for the test set\n",
        "\n",
        "print(test_data.tweet[0]) #print the first tweet\n",
        "print(probs[0]) # prints the prediction for the first tweet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@SouthwestAir get your damn act together. Don't announce we will be leaving on time after being delayed then delaying us again!\n",
            "[0.9910102 0.0089898]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}